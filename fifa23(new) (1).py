# -*- coding: utf-8 -*-
"""FIFA23(new).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cCENkVAYeEBaKvM4qNwbb6oGUcVjHnra
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

players22 = pd.read_csv('/content/drive/MyDrive/players_22.csv')

maleplayers = pd.read_csv('/content/drive/MyDrive/male_players (legacy).csv')

L = []
L_less = []
for i in maleplayers.columns:
    if((maleplayers[i].isnull().sum())<(0.3*(maleplayers.shape[0]))):
        L.append(i)
    else:
        L_less.append(i)
maleplayers = maleplayers[L]
maleplayers

maleplayers.info()

maleplayers.describe()

maleplayers.shape

maleplayers.columns

categorical_col=maleplayers.select_dtypes(exclude=np.number).columns
categorical_col

from sklearn.impute import SimpleImputer

numerical_col = maleplayers.select_dtypes(include=np.number).columns
numerical_impute = SimpleImputer(strategy='mean')
categorical_impute = SimpleImputer(strategy='constant')

maleplayers[numerical_col] =numerical_impute.fit_transform(maleplayers[numerical_col])
maleplayers[categorical_col] =categorical_impute.fit_transform(maleplayers[categorical_col])

male_categorical_col=maleplayers.select_dtypes(exclude=np.number)
datas = ['league_name','nationality_name']
male_categorical_col = male_categorical_col[datas]
male_categorical_col

from sklearn.preprocessing import LabelEncoder

for col in male_categorical_col.columns:
    male_categorical_col[col] = male_categorical_col[col].astype(str)

label_encoder = LabelEncoder()

for col in male_categorical_col.columns:
    male_categorical_col[col] = label_encoder.fit_transform(male_categorical_col[col])

male_categorical_col = pd.DataFrame(male_categorical_col)
print(male_categorical_col)

numerical_col = maleplayers.select_dtypes(include=np.number)
maleplayers= pd.concat([numerical_col, male_categorical_col], axis=1)
maleplayers.columns

corr_matrix = maleplayers.corr()['overall'].sort_values(ascending = False)
high_correlated = corr_matrix[abs(corr_matrix > 0.2)]
high_correlated

high_correlated = corr_matrix[abs(corr_matrix > 0.2)]
high_correlated

high_correlated = corr_matrix[abs(corr_matrix > 0.2)].index
scaled_corr = maleplayers[high_correlated]

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

male_scaler = scaler.fit_transform(scaled_corr.drop('overall', axis=1))

male_scaler_DF = pd.DataFrame(male_scaler, columns=scaled_corr.drop('overall', axis=1).columns)
print(male_scaler_DF.columns)
scaled = pd.concat([male_scaler_DF, scaled_corr['overall'].reset_index(drop=True)], axis=1)

wage_age = ['wage_eur','age']
scaled = scaled.drop(wage_age,axis=1)
print(scaled.columns)

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor

from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder

x = scaled.drop(columns=['overall'])
y = scaled['overall']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

models = {
    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),
    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
    'XGBoost': XGBRegressor(n_estimators=100, random_state=42)}

results = {}

for model_name, model in models.items():
    cv_scores = cross_val_score(model, x_train, y_train, cv=5, scoring='neg_mean_absolute_error')
    results[model_name] = cv_scores
    print(f"{model_name} CV Mean MAE: {-np.mean(cv_scores):.4f} | Std: {np.std(cv_scores):.4f}")

for model_name, model in models.items():
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    mae_score = mean_absolute_error(y_test, y_pred)
    rmse_score = np.sqrt(mean_squared_error(y_test, y_pred))
    print(f"{model_name} Test MAE: {mae_score:.4f} | Test RMSE:Â {rmse_score:.4f}")

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

# Define the parameter grid with reduced values
param_grid_rf = {
    'n_estimators': [50, 100],
    'max_depth': [ 5, 10],
    'min_samples_split': [2, 10]
}

print("\nGrid Search for RandomForest")
grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=3, scoring='neg_mean_absolute_error')
grid_search_rf.fit(x_train, y_train)
print(f"Optimal Parameters for RandomForest: {grid_search_rf.best_params_}")
print(f"Best Cross-Validation MAE for RandomForest: {-grid_search_rf.best_score_:.4f}")

best_rf = grid_search_rf.best_estimator_

import pickle as pkl

# Store the metrics
model_metrics = {}
model_metrics[model_name] = (mae_score, rmse_score)

# Determine the best model based on MAE
best_model_name = min(model_metrics, key=lambda k: model_metrics[k][0])
best_model = models[best_model_name]

print(f"Best Model: {best_model_name} | MAE: {model_metrics[best_model_name][0]:.4f} | RMSE: {model_metrics[best_model_name][1]:.4f}")

# Save the best model to a file
with open('best_model.pkl', 'wb') as f:
    pkl.dump(best_model,f)

players22.isnull().sum()

players22.info()

players22.describe()

players22.columns

L = []
L_less = []
for i in players22.columns:
    if((players22[i].isnull().sum())<(0.3*(players22.shape[0]))):
        L.append(i)
    else:
        L_less.append(i)
players22 = players22[L]
players22

players22.shape

numerical = players22.select_dtypes(include = np.number).columns
categorical = players22.select_dtypes(exclude = np.number).columns

numericalImpute = SimpleImputer(strategy = "median")
categoricalImpute = SimpleImputer(strategy = "constant")

players22[numerical] = numericalImpute.fit_transform(players22[numerical])
players22[categorical] = categoricalImpute.fit_transform(players22[categorical])

players22_nonnumeric = players22.select_dtypes(include=['object'])
players22_numeric = players22.select_dtypes(include= np.number)

players22_nonnumeric

players22_nonnumeric.columns

col_used = ['player_positions','club_name','nationality_name','work_rate']
players22_nonnumeric = players22_nonnumeric[col_used]
players22_nonnumeric

from sklearn.preprocessing import LabelEncoder

for col in players22_nonnumeric.columns:
    players22_nonnumeric[col] = players22_nonnumeric[col].astype(str)
labelencoder = LabelEncoder()

encodeCol = players22_nonnumeric.apply(lambda col: labelencoder.fit_transform(col))
encodeDF = pd.DataFrame(encodeCol, columns=players22_nonnumeric.columns)
label_encoders = {col: LabelEncoder().fit(players22_nonnumeric[col]) for col in players22_nonnumeric.columns}

print(encodeDF)

newplayers22 = pd.concat([players22_numeric.reset_index(drop=True), encodeDF.reset_index(drop=True)], axis=1)
relation = maleplayers.columns.intersection(newplayers22.columns)
newplayers22 = newplayers22[relation]

new_corr = newplayers22.corr()['overall'].sort_values(ascending=False)
new_corr

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled = scaler.fit_transform(newplayers22.drop('overall', axis=1))

scaledDF = pd.DataFrame(scaled, columns=newplayers22.drop('overall', axis=1).columns)
print(scaledDF)

male_players = pd.concat([scaledDF, newplayers22['overall'].reset_index(drop=True)], axis=1)

print(male_players)

players22.columns

#variable = 'overall'
#male_players = male_players.drop(columns=[variable])

#finalprediction = model.predict(male_players)
#np.set_printoptions(threshold=np.inf)
#finalprediction

male_players.columns

# Define the list of columns used during model training
trained_features = [
    'movement_reactions', 'potential', 'passing', 'mentality_composure',
    'value_eur', 'dribbling', 'attacking_short_passing', 'mentality_vision',
    'international_reputation', 'skill_long_passing', 'power_shot_power',
    'physic', 'skill_ball_control', 'shooting', 'skill_curve', 'power_long_shots',
    'mentality_aggression', 'attacking_crossing', 'skill_fk_accuracy',
    'attacking_volleys', 'skill_dribbling', 'power_stamina', 'power_strength',
    'mentality_positioning', 'attacking_heading_accuracy', 'mentality_penalties',
    'skill_moves', 'attacking_finishing', 'mentality_interceptions', 'defending',
    'power_jumping', 'defending_marking_awareness', 'movement_agility',
    'defending_standing_tackle', 'defending_sliding_tackle', 'weak_foot',
    'movement_sprint_speed'
]

# Select only the columns used during model training from the dataset
selected = maleplayers[trained_features]

# Predict using the selected features
finalprediction = model.predict(selected)

# Print the predictions
import numpy as np
np.set_printoptions(threshold=np.inf)
print(finalprediction)

